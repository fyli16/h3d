#!/bin/tcsh
#### Slurm job file for LANL Grizzly
#
#  predict the duration of the job
#SBATCH --time=8:00:00
#
#  request resources:  209 nodes
#  with 36 PEs each
#SBATCH --nodes=178
#SBATCH --ntasks-per-node=36
#
#  specify the pathname for output
#SBATCH --output ./output-gr
#
#  prject name
##SBATCH --account=w18_partacc
#SBATCH --account=w19_radbelts

module purge
module load gcc openmpi

set verbose
setenv OMP_NUM_THREADS 1

setenv DATA_DIRECTORY ./data
setenv RESTART_DIRECTORY ./restart_files
setenv INPUT_DIRECTORY ./
setenv SOURCE_DIRECTORY ./
mkdir -p $DATA_DIRECTORY
mkdir -p $RESTART_DIRECTORY
cp finput.dat $DATA_DIRECTORY/

setenv MPI_TYPE_MAX 65536
setenv MPI_REQUEST_MAX 65536
mpirun -np 6400 ./3dh 
echo 'Done'
